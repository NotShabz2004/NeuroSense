# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qvU2-E6rU2aO4z-a0QheOJcoMujrjAg-
"""

import zipfile

eeg_zip_path = "/content/drive/MyDrive/Datasets/archive.zip"
extract_path = "/content/eeg_data/"

with zipfile.ZipFile(eeg_zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# List files and folders inside EEG directory
!ls /content/eeg_data/

!ls /content/eeg_data/

import pandas as pd

eeg_df = pd.read_csv("/content/eeg_data/mental-state.csv")
print("Shape:", eeg_df.shape)
eeg_df.head()

eeg_df.info()

import zipfile

fer_zip = "/content/drive/MyDrive/Datasets/train.csv.zip"
fer_path = "/content/fer_data/"

with zipfile.ZipFile(fer_zip, 'r') as zip_ref:
    zip_ref.extractall(fer_path)

!ls /content/fer_data/

fer_df = pd.read_csv("/content/fer_data/train.csv")
fer_df.head()

import numpy as np

# Convert pixel strings to arrays
def process_pixels(pixels_str):
    pixels = np.array([int(p) for p in pixels_str.split()], dtype=np.uint8)
    return pixels.reshape(48, 48)  # image shape

fer_df['image_array'] = fer_df['pixels'].apply(process_pixels)

from sklearn.preprocessing import OneHotEncoder

# Fix: use sparse_output instead of sparse
emotion_enc = OneHotEncoder(sparse_output=False)
emotion_onehot = emotion_enc.fit_transform(fer_df[['emotion']])

import sklearn
print(sklearn.__version__)

from sklearn.preprocessing import OneHotEncoder

emotion_enc = OneHotEncoder(sparse_output=False)  # ✅ works for sklearn 1.2+
emotion_onehot = emotion_enc.fit_transform(fer_df[['emotion']])

from sklearn.preprocessing import OneHotEncoder

# ✅ Correct for scikit-learn 1.6.1
emotion_enc = OneHotEncoder(sparse_output=False)
emotion_onehot = emotion_enc.fit_transform(fer_df[['emotion']])

# Ensure both EEG and FER data have the same number of rows
min_len = min(len(eeg_df), len(emotion_onehot))

# EEG features (exclude 'Label' column)
X_eeg = eeg_df.iloc[:min_len, :-1].values

# Emotion one-hot vectors
X_emotion = emotion_onehot[:min_len]

# Labels (cognitive load: low, medium, high)
y = eeg_df.iloc[:min_len]['Label'].values

import numpy as np

# Combine EEG data with emotion data
X_combined = np.hstack((X_eeg, X_emotion))

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

# Train a simple classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predictions
y_pred = clf.predict(X_test)

# Evaluation
print(classification_report(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Check the label distribution
print("Unique Labels and Counts:")
print(eeg_df['Label'].value_counts())

# Optional: label names if applicable
label_map = {0: 'Low', 1: 'Medium', 2: 'High'}

# Match sizes of emotion and EEG
min_len = min(len(eeg_df), len(emotion_onehot))
X_eeg = eeg_df.iloc[:min_len, :-1].values
X_emotion = emotion_onehot[:min_len]
y = eeg_df.iloc[:min_len]['Label'].values

# Combine features
X_combined = np.hstack((X_eeg, X_emotion))

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y, test_size=0.2, random_state=42)

# Train model
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict
y_pred = clf.predict(X_test)

# 2. Print classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Low', 'Medium', 'High']))

# 3. Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# 4. Plot confusion matrix
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Low', 'Medium', 'High'],
            yticklabels=['Low', 'Medium', 'High'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Get a sample with emotion '3' = Happy
happy_sample = fer_df[fer_df['emotion'] == 3].iloc[0]
happy_pixels = np.array(list(map(int, happy_sample['pixels'].split()))).reshape(48, 48)

# One-hot encode the happy label
happy_emotion_onehot = emotion_enc.transform([[3]])  # 3 = happy

eeg_sample = eeg_df.iloc[0, :-1].values.reshape(1, -1)  # 1 EEG sample

# Combine EEG and emotion features
test_input = np.hstack((eeg_sample, happy_emotion_onehot))

# Predict cognitive load
prediction = clf.predict(test_input)[0]
label_map = {0: 'Low', 1: 'Medium', 2: 'High'}

print("Predicted Cognitive Load for Happy Expression:", label_map[prediction])

label_map = {0: 'Low', 1: 'Medium', 2: 'High'}

# Predict cognitive load
prediction = clf.predict(test_input)[0]

# Print the final label only
print(label_map[prediction])

# Mapping
emotion_names = {
    0: 'Angry',
    1: 'Disgust',
    2: 'Fear',
    3: 'Happy',
    4: 'Sad',
    5: 'Surprise',
    6: 'Neutral'
}

cognitive_load_labels = {0: 'Low', 1: 'Medium', 2: 'High'}

# Use the same EEG feature for all (e.g., first one from mental-state.csv)
eeg_sample = eeg_df.iloc[0, :-1].values.reshape(1, -1)

# Iterate over all emotions
for emotion_code in range(7):
    # Get one sample of this emotion
    sample = fer_df[fer_df['emotion'] == emotion_code].iloc[0]

    # One-hot encode emotion
    emotion_onehot = emotion_enc.transform(pd.DataFrame({'emotion': [emotion_code]}))

    # Combine EEG and emotion
    combined_input = np.hstack((eeg_sample, emotion_onehot))

    # Predict
    prediction = clf.predict(combined_input)[0]

    # Print result
    print(f"Expression: {emotion_names[emotion_code]} → Cognitive Load: {cognitive_load_labels[prediction]}")

import os

# Check files inside extracted folder
!unzip -l /content/drive/MyDrive/Datasets/archive.zip

# Step 1: Unzip the archive into /content/
!unzip -o /content/drive/MyDrive/Datasets/archive.zip -d /content/

# Step 2: Load the mental-state.csv file
import pandas as pd

df = pd.read_csv("/content/mental-state.csv")

# Step 3: Show distribution of cognitive load labels
print("Label Distribution:")
print(df['Label'].value_counts())

import os

path = "/content/drive/MyDrive/Datasets"
for file in os.listdir(path):
    print(file)

import zipfile

zip_path = "/content/drive/MyDrive/Datasets/train.csv.zip"
extract_to = "/content/drive/MyDrive/Datasets/"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

import os

for file in os.listdir("/content/drive/MyDrive/Datasets/"):
    print(file)

import pandas as pd

fer_df = pd.read_csv("/content/drive/MyDrive/Datasets/train.csv")
fer_df.head()

expression_map = {
    0: "Angry",
    1: "Disgust",
    2: "Fear",
    3: "Happy",
    4: "Sad",
    5: "Surprise",
    6: "Neutral"
}

fer_df["expression"] = fer_df["emotion"].map(expression_map)

import numpy as np

def process_pixels(pixels_str):
    pixels = np.array([int(p) for p in pixels_str.split()])
    return pixels / 255.0  # Normalize to [0, 1]

fer_df["pixel_array"] = fer_df["pixels"].apply(process_pixels)

# Simulated mapping (example assumption)
emotion_to_cogload = {
    "Angry": "High",
    "Disgust": "High",
    "Fear": "High",
    "Sad": "High",
    "Surprise": "Medium",
    "Happy": "Low",
    "Neutral": "Medium"
}

fer_df["cognitive_load"] = fer_df["expression"].map(emotion_to_cogload)

fer_df[["expression", "cognitive_load"]].drop_duplicates().sort_values("expression")

import zipfile

zip_path = "/content/drive/MyDrive/Datasets/train.csv.zip"  # adjust if needed

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content")  # or your desired path

import pandas as pd

df = pd.read_csv("/content/train.csv")
df.head()

import pandas as pd

# Load the dataset
fer_df = pd.read_csv("/content/train.csv")

# Map labels to emotion names
emotion_map = {
    0: "Angry",
    1: "Disgust",
    2: "Fear",
    3: "Happy",
    4: "Sad",
    5: "Surprise",
    6: "Neutral"
}

fer_df["emotion_label"] = fer_df["emotion"].map(emotion_map)

# Display the first few rows
fer_df[["emotion", "emotion_label"]].head()

fer_df["emotion_label"].value_counts()

import pandas as pd

# Load both datasets
fer_df = pd.read_csv("/content/train.csv")  # Facial emotion dataset
eeg_df = pd.read_csv("/content/mental-state.csv")  # EEG cognitive load dataset

# Map numerical emotion labels to text labels
emotion_map = {
    0: "Angry", 1: "Disgust", 2: "Fear", 3: "Happy",
    4: "Sad", 5: "Surprise", 6: "Neutral"
}
fer_df['emotion_label'] = fer_df['emotion'].map(emotion_map)

# Truncate both datasets to the same length
min_len = min(len(fer_df), len(eeg_df))
fer_df = fer_df.iloc[:min_len].reset_index(drop=True)
eeg_df = eeg_df.iloc[:min_len].reset_index(drop=True)

# Combine both datasets
merged_df = pd.concat([fer_df, eeg_df[['Label']]], axis=1)

# Map cognitive load label to text
cognitive_map = {0.0: "Low", 1.0: "Medium", 2.0: "High"}
merged_df['Cognitive Load'] = merged_df['Label'].map(cognitive_map)

# Group by emotion and cognitive load
load_by_emotion = merged_df.groupby('emotion_label')['Cognitive Load'].value_counts().unstack().fillna(0).astype(int)

# Display result
print("Cognitive Load Distribution by Emotion:")
print(load_by_emotion)

!pip install fer

from fer import FER
import matplotlib.pyplot as plt
import cv2

# Load image
img = cv2.imread("/content/drive/MyDrive/Datasets/images.jpeg")
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Detect emotion
detector = FER(mtcnn=True)
result = detector.detect_emotions(img_rgb)

# Show image
plt.imshow(img_rgb)
plt.axis('off')
plt.show()

# Print emotion result
if result:
    print("Top emotion:", detector.top_emotion(img_rgb))
else:
    print("No face detected.")

from fer import FER
import matplotlib.pyplot as plt
import cv2
import numpy as np

# Load image
img_path = "/content/drive/MyDrive/Datasets/images.jpeg"
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Detect emotion
detector = FER(mtcnn=True)
result = detector.detect_emotions(img_rgb)

# Determine top emotion
if result:
    top_emotion, score = detector.top_emotion(img_rgb)
else:
    top_emotion = "No face detected"
    score = 0.0

# Brain load mapping based on emotion
emotion_to_brain_load = {
    "happy": "Low",
    "neutral": "Neutral",
    "sad": "High",
    "angry": "High",
    "fear": "High",
    "disgust": "High",
    "surprise": "Neutral"
}

# Get brain load
brain_load = emotion_to_brain_load.get(top_emotion.lower(), "Neutral")

# Display image with emotion and brain load
plt.figure(figsize=(6, 6))
plt.imshow(img_rgb)
plt.axis('off')
plt.title(f"Emotion: {top_emotion} ({score*100:.1f}%)\n🧠 Brain Load: {brain_load}")
plt.show()

# Print summary
print(f"🖼️ Emotion Detected: {top_emotion}")
print(f"📊 Brain Load: {brain_load}")

from fer import FER
import matplotlib.pyplot as plt
import cv2
import numpy as np
import pandas as pd

# List of image paths
image_paths = [
    "/content/drive/MyDrive/Datasets/IMG_3683.jpg",
    "/content/drive/MyDrive/Datasets/IMG_3684.jpg"
]

# Brain load mapping
emotion_to_brain_load = {
    "happy": "Low",
    "neutral": "Neutral",
    "sad": "High",
    "angry": "High",
    "fear": "High",
    "disgust": "High",
    "surprise": "Neutral"
}

# FER detector
detector = FER(mtcnn=True)

# Store results
results = []

for img_path in image_paths:
    # Load image
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Detect emotion
    result = detector.detect_emotions(img_rgb)

    if result:
        top_emotion, score = detector.top_emotion(img_rgb)
        brain_load = emotion_to_brain_load.get(top_emotion.lower(), "Neutral")
    else:
        top_emotion = "No face detected"
        score = 0.0
        brain_load = "Unknown"

    # Display image with title
    plt.figure(figsize=(6, 6))
    plt.imshow(img_rgb)
    plt.axis('off')
    plt.title(f"Emotion: {top_emotion} ({score*100:.1f}%)\n🧠 Brain Load: {brain_load}")
    plt.show()

    # Save result
    results.append({
        "Image": img_path.split("/")[-1],
        "Emotion": top_emotion.capitalize(),
        "Confidence (%)": round(score * 100, 1),
        "Brain Load": brain_load
    })

# Show results in a table
df = pd.DataFrame(results)
print(df)

from fer import FER
import matplotlib.pyplot as plt
import cv2

# List of image paths (you can update these paths)
image_paths = [
    "/content/drive/MyDrive/Datasets/IMG_3683.jpg",
    "/content/drive/MyDrive/Datasets/IMG_3684.jpg",
    "/content/drive/MyDrive/Datasets/images.jpeg"  # Existing image
]

# Initialize FER detector
detector = FER(mtcnn=True)

# Set up subplots
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Loop through each image
for i, img_path in enumerate(image_paths):
    # Load and convert image
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Detect emotions
    results = detector.detect_emotions(img_rgb)

    if results:
        emotions = results[0]['emotions']
        axes[i].bar(emotions.keys(), emotions.values(), color='skyblue')
        axes[i].set_ylim(0, 1)
        axes[i].set_title(f"Image {i+1}: Top - {detector.top_emotion(img_rgb)[0].capitalize()}")
        axes[i].tick_params(axis='x', rotation=45)
    else:
        axes[i].text(0.5, 0.5, "No face detected", ha='center', va='center', fontsize=12)
        axes[i].set_xticks([])
        axes[i].set_yticks([])
        axes[i].set_title(f"Image {i+1}: No Face")

# Global figure settings
plt.suptitle("Emotion Confidence Scores for 3 Images", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score
import numpy as np

# Load your trained model
model = load_model("cnn_model.h5")

# Load your test data (features and labels)
# Example: X_test shape = (num_samples, height, width, channels)
#          y_test shape = (num_samples,)
X_test = np.load("X_test.npy")
y_test = np.load("y_test.npy")

# Predict
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print(f"✅ Model Accuracy: {acc * 100:.2f}%")